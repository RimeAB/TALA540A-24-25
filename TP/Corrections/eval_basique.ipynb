{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8801038-32aa-459d-8e0e-d58ae88137d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: fr_core_news_sm\n",
      "Tagging completed.\n",
      "annodis\n",
      "Accuracy: 0.9613, OOV Accuracy: 0.8586\n",
      "frwiki\n",
      "Accuracy: 0.9577, OOV Accuracy: 0.7281\n",
      "emea\n",
      "Accuracy: 0.9770, OOV Accuracy: 0.7870\n",
      "Europar\n",
      "Accuracy: 0.9591, OOV Accuracy: 0.7692\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.90      0.90      0.90       638\n",
      "         ADP       0.99      1.00      0.99      1634\n",
      "         ADV       0.98      0.96      0.97       411\n",
      "         AUX       0.98      0.99      0.98       345\n",
      "       CCONJ       0.99      1.00      0.99       221\n",
      "         DET       0.99      0.98      0.99      1492\n",
      "        NOUN       0.94      0.97      0.95      2161\n",
      "         NUM       0.97      0.97      0.97       243\n",
      "        PRON       0.97      0.95      0.96       410\n",
      "       PROPN       0.90      0.91      0.91       478\n",
      "       PUNCT       1.00      1.00      1.00      1084\n",
      "       SCONJ       0.93      0.94      0.94       106\n",
      "         SYM       1.00      0.50      0.67         4\n",
      "        VERB       0.95      0.91      0.93       781\n",
      "           X       0.50      0.11      0.18        36\n",
      "\n",
      "    accuracy                           0.96     10044\n",
      "   macro avg       0.93      0.87      0.89     10044\n",
      "weighted avg       0.96      0.96      0.96     10044\n",
      "\n",
      "Running model: fr_core_news_md\n",
      "Tagging completed.\n",
      "annodis\n",
      "Accuracy: 0.9757, OOV Accuracy: 0.9394\n",
      "frwiki\n",
      "Accuracy: 0.9713, OOV Accuracy: 0.8812\n",
      "emea\n",
      "Accuracy: 0.9788, OOV Accuracy: 0.8698\n",
      "Europar\n",
      "Accuracy: 0.9754, OOV Accuracy: 0.9060\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.94      0.96      0.95       638\n",
      "         ADP       0.99      1.00      0.99      1634\n",
      "         ADV       0.98      0.97      0.98       411\n",
      "         AUX       0.98      0.98      0.98       345\n",
      "       CCONJ       1.00      0.98      0.99       221\n",
      "         DET       0.99      0.98      0.99      1492\n",
      "        NOUN       0.97      0.98      0.97      2161\n",
      "         NUM       0.98      0.96      0.97       243\n",
      "        PRON       0.96      0.95      0.96       410\n",
      "       PROPN       0.93      0.93      0.93       478\n",
      "       PUNCT       1.00      1.00      1.00      1084\n",
      "       SCONJ       0.96      0.92      0.94       106\n",
      "         SYM       0.67      0.50      0.57         4\n",
      "        VERB       0.96      0.96      0.96       781\n",
      "           X       0.79      0.53      0.63        36\n",
      "\n",
      "    accuracy                           0.98     10044\n",
      "   macro avg       0.94      0.91      0.92     10044\n",
      "weighted avg       0.97      0.98      0.97     10044\n",
      "\n",
      "Running model: fr_core_news_lg\n",
      "Tagging completed.\n",
      "annodis\n",
      "Accuracy: 0.9769, OOV Accuracy: 0.9343\n",
      "frwiki\n",
      "Accuracy: 0.9737, OOV Accuracy: 0.8875\n",
      "emea\n",
      "Accuracy: 0.9843, OOV Accuracy: 0.8817\n",
      "Europar\n",
      "Accuracy: 0.9762, OOV Accuracy: 0.9188\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.94      0.97      0.95       638\n",
      "         ADP       0.99      1.00      0.99      1634\n",
      "         ADV       0.98      0.98      0.98       411\n",
      "         AUX       0.98      0.99      0.98       345\n",
      "       CCONJ       0.99      1.00      0.99       221\n",
      "         DET       0.99      0.99      0.99      1492\n",
      "        NOUN       0.97      0.98      0.97      2161\n",
      "         NUM       0.98      0.98      0.98       243\n",
      "        PRON       0.97      0.96      0.97       410\n",
      "       PROPN       0.94      0.93      0.93       478\n",
      "       PUNCT       1.00      1.00      1.00      1084\n",
      "       SCONJ       0.94      0.92      0.93       106\n",
      "         SYM       1.00      0.50      0.67         4\n",
      "        VERB       0.98      0.96      0.97       781\n",
      "           X       0.76      0.53      0.62        36\n",
      "\n",
      "    accuracy                           0.98     10044\n",
      "   macro avg       0.96      0.91      0.93     10044\n",
      "weighted avg       0.98      0.98      0.98     10044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Set, Tuple\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import spacy\n",
    "from pyJoules.energy_meter import measure_energy\n",
    "from sklearn.metrics import classification_report\n",
    "from spacy.tokens import Doc as SpacyDoc\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    form: str\n",
    "    tag: str\n",
    "    is_oov: bool\n",
    "\n",
    "@dataclass\n",
    "class Sentence:\n",
    "    sent_id: str\n",
    "    tokens: List[Token]\n",
    "\n",
    "@dataclass\n",
    "class Corpus:\n",
    "    sentences: List[Sentence]\n",
    "\n",
    "def read_conll(path: Path, vocabulaire: Optional[Set[str]] = None) -> Corpus:\n",
    "    sentences: List[Sentence] = []\n",
    "    tokens: List[Token] = []\n",
    "    sid = \"\"\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"# sent_id =\"):\n",
    "                sid = line.split(\" \")[-1]\n",
    "            if not line.startswith(\"#\"):\n",
    "                if line == \"\":\n",
    "                    if tokens:  # Ensure we only append non-empty tokens\n",
    "                        sentences.append(Sentence(sent_id=sid, tokens=tokens))\n",
    "                        tokens = []\n",
    "                else:\n",
    "                    fields = line.split(\"\\t\")\n",
    "                    form, tag = fields[1], fields[3]\n",
    "                    if \"-\" not in fields[0]:  # Avoid contractions like \"du\"\n",
    "                        is_oov = form not in vocabulaire if vocabulaire else True\n",
    "                        tokens.append(Token(form, tag, is_oov))\n",
    "    return Corpus(sentences)\n",
    "\n",
    "# Build vocabulary from the corpus\n",
    "def build_vocabulaire(corpus: Corpus) -> Set[str]:\n",
    "    return {tok.form for sent in corpus.sentences for tok in sent.tokens}\n",
    "\n",
    "# Convert a sentence to a spaCy Doc\n",
    "def sentence_to_doc(sentence: Sentence, vocab) -> SpacyDoc:\n",
    "    words = [tok.form for tok in sentence.tokens]\n",
    "    return SpacyDoc(vocab, words=words)\n",
    "\n",
    "# Convert a spaCy Doc back to a sentence\n",
    "def doc_to_sentence(doc: SpacyDoc, origin: Sentence) -> Sentence:\n",
    "    tokens = [\n",
    "        Token(tok.text, tok.pos_ or tok.tag_, origin_token.is_oov) \n",
    "        for tok, origin_token in zip(doc, origin.tokens)\n",
    "    ]\n",
    "    return Sentence(origin.sent_id, tokens)\n",
    "\n",
    "# Run spaCy POS tagging model on the corpus and measure energy consumption\n",
    "#@measure_energy  # error on MacOS\n",
    "def tag_corpus_spacy(corpus: Corpus, model_spacy) -> Corpus:\n",
    "    sentences = []\n",
    "    for sentence in corpus.sentences:\n",
    "        doc = sentence_to_doc(sentence, model_spacy.vocab)\n",
    "        doc = model_spacy(doc)\n",
    "        sentences.append(doc_to_sentence(doc, sentence))\n",
    "    return Corpus(sentences)\n",
    "\n",
    "# Compute accuracy in token level, including OOV words\n",
    "def compute_accuracy(corpus_gold: Corpus, corpus_test: Corpus, subcorpus: Optional[str] = None) -> Tuple[float, float]:\n",
    "    nb_ok, nb_total, oov_ok, oov_total = 0, 0, 0, 0\n",
    "    for sentence_gold, sentence_test in zip(corpus_gold.sentences, corpus_test.sentences):\n",
    "        if subcorpus is None or subcorpus in sentence_gold.sent_id:\n",
    "            for token_gold, token_test in zip(sentence_gold.tokens, sentence_test.tokens):\n",
    "                assert token_gold.form == token_test.form  # Ensure forms match\n",
    "                nb_total += 1  # Increment total count\n",
    "                if token_gold.tag == token_test.tag:  # Check if tags match\n",
    "                    nb_ok += 1\n",
    "                if token_gold.is_oov:  # Check if token is OOV\n",
    "                    oov_total += 1\n",
    "                    if token_gold.tag == token_test.tag:  # Check if OOV tags match\n",
    "                        oov_ok += 1\n",
    "    \n",
    "    accuracy = nb_ok / nb_total if nb_total > 0 else 0.0\n",
    "    oov_accuracy = oov_ok / oov_total if oov_total > 0 else 0.0\n",
    "    \n",
    "    return accuracy, oov_accuracy\n",
    "\n",
    "# Print classification report\n",
    "def print_report(corpus_gold: Corpus, corpus_test: Corpus):\n",
    "    ref = [tok.tag for sent in corpus_gold.sentences for tok in sent.tokens]\n",
    "    test = [tok.tag for sent in corpus_test.sentences for tok in sent.tokens]\n",
    "    print(classification_report(ref, test))\n",
    "\n",
    "def run_evaluation(train_path: str, test_path: str, model_names: List[str]):\n",
    "    corpus_train = read_conll(Path(train_path))\n",
    "    vocab_train = build_vocabulaire(corpus_train)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"Running model: {model_name}\")\n",
    "        model_spacy = spacy.load(model_name)\n",
    "\n",
    "        corpus_gold = read_conll(Path(test_path), vocabulaire=vocab_train)\n",
    "        corpus_test = tag_corpus_spacy(corpus_gold, model_spacy)\n",
    "\n",
    "        print(\"Tagging completed.\")\n",
    "        for subcorpus in (\"annodis\", \"frwiki\", \"emea\", \"Europar\"):\n",
    "            print(subcorpus)\n",
    "            accuracy, oov_accuracy = compute_accuracy(corpus_gold, corpus_test, subcorpus)\n",
    "            print(f\"Accuracy: {accuracy:.4f}, OOV Accuracy: {oov_accuracy:.4f}\")\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print_report(corpus_gold, corpus_test)\n",
    "\n",
    "def evaluate_models():\n",
    "    model_names = [\"fr_core_news_sm\", \"fr_core_news_md\", \"fr_core_news_lg\"]\n",
    "    train_path = \"fr_sequoia-ud-train.conllu\"\n",
    "    test_path = \"fr_sequoia-ud-test.conllu\"\n",
    "    run_evaluation(train_path, test_path, model_names)\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_models()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
